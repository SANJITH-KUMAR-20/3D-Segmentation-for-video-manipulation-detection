{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9TE8IDGLbsXw",
    "outputId": "d7b383cb-c71f-4cad-abd1-5b3b35972eb0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: av in /home/praveenbenedict/miniconda3/envs/deepcheck-faceswap-video-seg/lib/python3.9/site-packages (11.0.0)\n",
      "Requirement already satisfied: facenet_pytorch in /home/praveenbenedict/miniconda3/envs/deepcheck-faceswap-video-seg/lib/python3.9/site-packages (2.5.3)\n",
      "Requirement already satisfied: numpy in /home/praveenbenedict/miniconda3/envs/deepcheck-faceswap-video-seg/lib/python3.9/site-packages (from facenet_pytorch) (1.26.4)\n",
      "Requirement already satisfied: requests in /home/praveenbenedict/miniconda3/envs/deepcheck-faceswap-video-seg/lib/python3.9/site-packages (from facenet_pytorch) (2.31.0)\n",
      "Requirement already satisfied: torchvision in /home/praveenbenedict/miniconda3/envs/deepcheck-faceswap-video-seg/lib/python3.9/site-packages (from facenet_pytorch) (0.17.1)\n",
      "Requirement already satisfied: pillow in /home/praveenbenedict/miniconda3/envs/deepcheck-faceswap-video-seg/lib/python3.9/site-packages (from facenet_pytorch) (10.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/praveenbenedict/miniconda3/envs/deepcheck-faceswap-video-seg/lib/python3.9/site-packages (from requests->facenet_pytorch) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/praveenbenedict/miniconda3/envs/deepcheck-faceswap-video-seg/lib/python3.9/site-packages (from requests->facenet_pytorch) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/praveenbenedict/miniconda3/envs/deepcheck-faceswap-video-seg/lib/python3.9/site-packages (from requests->facenet_pytorch) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/praveenbenedict/miniconda3/envs/deepcheck-faceswap-video-seg/lib/python3.9/site-packages (from requests->facenet_pytorch) (2024.2.2)\n",
      "Requirement already satisfied: torch in /home/praveenbenedict/miniconda3/envs/deepcheck-faceswap-video-seg/lib/python3.9/site-packages (from torchvision->facenet_pytorch) (2.2.1)\n",
      "Requirement already satisfied: filelock in /home/praveenbenedict/miniconda3/envs/deepcheck-faceswap-video-seg/lib/python3.9/site-packages (from torch->torchvision->facenet_pytorch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/praveenbenedict/miniconda3/envs/deepcheck-faceswap-video-seg/lib/python3.9/site-packages (from torch->torchvision->facenet_pytorch) (4.9.0)\n",
      "Requirement already satisfied: sympy in /home/praveenbenedict/miniconda3/envs/deepcheck-faceswap-video-seg/lib/python3.9/site-packages (from torch->torchvision->facenet_pytorch) (1.12)\n",
      "Requirement already satisfied: networkx in /home/praveenbenedict/miniconda3/envs/deepcheck-faceswap-video-seg/lib/python3.9/site-packages (from torch->torchvision->facenet_pytorch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /home/praveenbenedict/miniconda3/envs/deepcheck-faceswap-video-seg/lib/python3.9/site-packages (from torch->torchvision->facenet_pytorch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /home/praveenbenedict/miniconda3/envs/deepcheck-faceswap-video-seg/lib/python3.9/site-packages (from torch->torchvision->facenet_pytorch) (2024.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/praveenbenedict/miniconda3/envs/deepcheck-faceswap-video-seg/lib/python3.9/site-packages (from jinja2->torch->torchvision->facenet_pytorch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/praveenbenedict/miniconda3/envs/deepcheck-faceswap-video-seg/lib/python3.9/site-packages (from sympy->torch->torchvision->facenet_pytorch) (1.3.0)\n",
      "Requirement already satisfied: ffmpeg-python in /home/praveenbenedict/miniconda3/envs/deepcheck-faceswap-video-seg/lib/python3.9/site-packages (0.2.0)\n",
      "Requirement already satisfied: future in /home/praveenbenedict/miniconda3/envs/deepcheck-faceswap-video-seg/lib/python3.9/site-packages (from ffmpeg-python) (1.0.0)\n",
      "Requirement already satisfied: matplotlib in /home/praveenbenedict/miniconda3/envs/deepcheck-faceswap-video-seg/lib/python3.9/site-packages (3.8.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/praveenbenedict/miniconda3/envs/deepcheck-faceswap-video-seg/lib/python3.9/site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/praveenbenedict/miniconda3/envs/deepcheck-faceswap-video-seg/lib/python3.9/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/praveenbenedict/miniconda3/envs/deepcheck-faceswap-video-seg/lib/python3.9/site-packages (from matplotlib) (4.49.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/praveenbenedict/miniconda3/envs/deepcheck-faceswap-video-seg/lib/python3.9/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in /home/praveenbenedict/miniconda3/envs/deepcheck-faceswap-video-seg/lib/python3.9/site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/praveenbenedict/miniconda3/envs/deepcheck-faceswap-video-seg/lib/python3.9/site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in /home/praveenbenedict/miniconda3/envs/deepcheck-faceswap-video-seg/lib/python3.9/site-packages (from matplotlib) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/praveenbenedict/miniconda3/envs/deepcheck-faceswap-video-seg/lib/python3.9/site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/praveenbenedict/miniconda3/envs/deepcheck-faceswap-video-seg/lib/python3.9/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /home/praveenbenedict/miniconda3/envs/deepcheck-faceswap-video-seg/lib/python3.9/site-packages (from matplotlib) (6.1.3)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /home/praveenbenedict/miniconda3/envs/deepcheck-faceswap-video-seg/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.17.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/praveenbenedict/miniconda3/envs/deepcheck-faceswap-video-seg/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install av\n",
    "!pip install facenet_pytorch\n",
    "!pip install ffmpeg-python\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "eW__GbyMeZAU"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Asus\\Desktop\\Phosphene.AI\\sizeinvar_timesformer\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import transforms\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import cv2\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "import numpy as np\n",
    "import facenet_pytorch\n",
    "import matplotlib.pyplot as plt\n",
    "import ffmpeg\n",
    "import torchvision.io as tio\n",
    "import av\n",
    "from torchvision.models.detection import maskrcnn_resnet50_fpn\n",
    "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
    "from torchvision.models.video import r3d_18\n",
    "from torchvision.transforms import functional as F\n",
    "from torchvision import transforms\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "4qhbsUY7eZDM"
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "#zip_file = \"/content/drive/MyDrive/Phosphene/sample_data.zip\"\n",
    "#with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
    "#        zip_ref.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "4Cj25WkQexZE"
   },
   "outputs": [],
   "source": [
    "train_dir = \"sample_data/target/train\"\n",
    "val_dir = \"sample_data/target/val\"\n",
    "train_mask_dir = \"sample_data/target_mask/train\"\n",
    "val_mask_dir = \"sample_data/target_mask/val\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "id": "G4F8jVnaexrk"
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((128, 171)),\n",
    "    transforms.Normalize(mean=[0.43216, 0.394666, 0.37645],\n",
    "                         std=[0.22803, 0.22145, 0.216989])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "id": "BgvqLluUeZJE"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class VideoDataset(Dataset):\n",
    "    def __init__(self, directory, target_dir, transform=None, frame_rate=24, pick_only=24):\n",
    "        self.directory = directory\n",
    "        self.target_dir = target_dir\n",
    "        self.transform = transform\n",
    "        self.frame_rate = frame_rate\n",
    "        self.pick_only = pick_only\n",
    "\n",
    "        self.videos = sorted(os.listdir(self.directory))\n",
    "        self.masks = sorted(os.listdir(self.target_dir))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.videos)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        video_path = os.path.join(self.directory, self.videos[idx])\n",
    "        mask_path = os.path.join(self.target_dir, self.masks[idx])\n",
    "    \n",
    "        video_frames, mask_frames = self.extract_frames(video_path, mask_path)\n",
    "        \n",
    "        if self.transform:\n",
    "            video_frames = [self.transform(frame) for frame in video_frames]\n",
    "            mask_frames = [self.transform(frame) for frame in mask_frames]\n",
    "\n",
    "        video_frames = torch.stack(video_frames).permute(1, 0, 2, 3)\n",
    "        mask_frames = torch.stack(mask_frames).permute(1, 0, 2, 3)\n",
    "\n",
    "        return video_frames, mask_frames\n",
    "\n",
    "    def extract_frames(self, video_path, mask_path):\n",
    "        cap_video = cv2.VideoCapture(video_path)\n",
    "        cap_mask = cv2.VideoCapture(mask_path)\n",
    "        frame_count = int(cap_video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        desired_frame_count = self.pick_only\n",
    "        \n",
    "        # Pick a random starting point within the video \n",
    "        start_idx = random.randint(0, max(0, frame_count - desired_frame_count))\n",
    "        \n",
    "        video_frames = []\n",
    "        mask_frames = []\n",
    "        \n",
    "        cap_video.set(cv2.CAP_PROP_POS_FRAMES, start_idx)  \n",
    "        cap_mask.set(cv2.CAP_PROP_POS_FRAMES, start_idx)  \n",
    "        \n",
    "        for i in range(desired_frame_count):\n",
    "            ret_video, frame_video = cap_video.read()\n",
    "            ret_mask, frame_mask = cap_mask.read()\n",
    "            if not (ret_video and ret_mask):\n",
    "                break\n",
    "            frame_video = cv2.cvtColor(frame_video, cv2.COLOR_BGR2RGB)\n",
    "            frame_mask = cv2.cvtColor(frame_mask, cv2.COLOR_BGR2GRAY)\n",
    "            video_frames.append(frame_video)\n",
    "            \n",
    "            mask_frames.append(frame_mask)\n",
    "           \n",
    "        \n",
    "        cap_video.release()\n",
    "        cap_mask.release()\n",
    "        return video_frames, mask_frames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "id": "Rm4U0K_2eZL9"
   },
   "outputs": [],
   "source": [
    "train_dataset = VideoDataset(train_dir, target_dir=train_mask_dir, transform=transform)\n",
    "val_dataset = VideoDataset(val_dir, target_dir=val_mask_dir,transform=transform)\n",
    "\n",
    "batch_size = 1\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZmgRvtsjeZO7",
    "outputId": "d88f66ec-8fc4-4fa9-d46d-19202df99e34"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = None\n",
    "count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tWgEBEpReZR0",
    "outputId": "669cc75e-07d2-4f11-8c1a-f32783e078bf"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "output with shape [1, 128, 171] doesn't match the broadcast shape [3, 128, 171]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[134], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mvideos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmasks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvideo\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mvideos\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcount\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m:\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Asus\\Desktop\\Phosphene.AI\\sizeinvar_timesformer\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\Asus\\Desktop\\Phosphene.AI\\sizeinvar_timesformer\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\Asus\\Desktop\\Phosphene.AI\\sizeinvar_timesformer\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\Asus\\Desktop\\Phosphene.AI\\sizeinvar_timesformer\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn[131], line 25\u001b[0m, in \u001b[0;36mVideoDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform:\n\u001b[0;32m     24\u001b[0m     video_frames \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(frame) \u001b[38;5;28;01mfor\u001b[39;00m frame \u001b[38;5;129;01min\u001b[39;00m video_frames]\n\u001b[1;32m---> 25\u001b[0m     mask_frames \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmask_frames\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     27\u001b[0m video_frames \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(video_frames)\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m     28\u001b[0m mask_frames \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(mask_frames)\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n",
      "Cell \u001b[1;32mIn[131], line 25\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform:\n\u001b[0;32m     24\u001b[0m     video_frames \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(frame) \u001b[38;5;28;01mfor\u001b[39;00m frame \u001b[38;5;129;01min\u001b[39;00m video_frames]\n\u001b[1;32m---> 25\u001b[0m     mask_frames \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m frame \u001b[38;5;129;01min\u001b[39;00m mask_frames]\n\u001b[0;32m     27\u001b[0m video_frames \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(video_frames)\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m     28\u001b[0m mask_frames \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(mask_frames)\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Asus\\Desktop\\Phosphene.AI\\sizeinvar_timesformer\\Lib\\site-packages\\torchvision\\transforms\\transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[1;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[1;32mc:\\Users\\Asus\\Desktop\\Phosphene.AI\\sizeinvar_timesformer\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Asus\\Desktop\\Phosphene.AI\\sizeinvar_timesformer\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Asus\\Desktop\\Phosphene.AI\\sizeinvar_timesformer\\Lib\\site-packages\\torchvision\\transforms\\transforms.py:277\u001b[0m, in \u001b[0;36mNormalize.forward\u001b[1;34m(self, tensor)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, tensor: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m    270\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    271\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m    272\u001b[0m \u001b[38;5;124;03m        tensor (Tensor): Tensor image to be normalized.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;124;03m        Tensor: Normalized Tensor image.\u001b[39;00m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Asus\\Desktop\\Phosphene.AI\\sizeinvar_timesformer\\Lib\\site-packages\\torchvision\\transforms\\functional.py:349\u001b[0m, in \u001b[0;36mnormalize\u001b[1;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensor, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m    347\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimg should be Tensor Image. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(tensor)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 349\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF_t\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmean\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Asus\\Desktop\\Phosphene.AI\\sizeinvar_timesformer\\Lib\\site-packages\\torchvision\\transforms\\_functional_tensor.py:926\u001b[0m, in \u001b[0;36mnormalize\u001b[1;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[0;32m    924\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m std\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    925\u001b[0m     std \u001b[38;5;241m=\u001b[39m std\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m--> 926\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msub_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdiv_(std)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: output with shape [1, 128, 171] doesn't match the broadcast shape [3, 128, 171]"
     ]
    }
   ],
   "source": [
    "for videos, masks in train_loader:\n",
    "    video = videos\n",
    "    if count == 3:\n",
    "        break\n",
    "    count += 1\n",
    "    print(\"Video batch shape:\", videos.shape)\n",
    "    print(\"Mask batch shape:\", masks.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 24, 224, 224])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B9e1OJTkeZUr",
    "outputId": "3f0ed097-2787-4015-d58b-18e69fa13019"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(517, 102)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset),len(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Asus\\Desktop\\Phosphene.AI\\sizeinvar_timesformer\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Asus\\Desktop\\Phosphene.AI\\sizeinvar_timesformer\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=R3D_18_Weights.KINETICS400_V1`. You can also use `weights=R3D_18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "pretrained = r3d_18(pretrained = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "modules = list(pretrained.modules())\n",
    "\n",
    "pretrained_sequential = nn.Sequential()\n",
    "\n",
    "for _, module in enumerate(modules):\n",
    "    pretrained_sequential.add_module('module' + str(_), module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "modules = list(modules[0].modules())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modules[0].get_submodule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[VideoResNet(\n",
       "   (stem): BasicStem(\n",
       "     (0): Conv3d(3, 64, kernel_size=(3, 7, 7), stride=(1, 2, 2), padding=(1, 3, 3), bias=False)\n",
       "     (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (2): ReLU(inplace=True)\n",
       "   )\n",
       "   (layer1): Sequential(\n",
       "     (0): BasicBlock(\n",
       "       (conv1): Sequential(\n",
       "         (0): Conv3DSimple(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "         (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (2): ReLU(inplace=True)\n",
       "       )\n",
       "       (conv2): Sequential(\n",
       "         (0): Conv3DSimple(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "         (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       )\n",
       "       (relu): ReLU(inplace=True)\n",
       "     )\n",
       "     (1): BasicBlock(\n",
       "       (conv1): Sequential(\n",
       "         (0): Conv3DSimple(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "         (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (2): ReLU(inplace=True)\n",
       "       )\n",
       "       (conv2): Sequential(\n",
       "         (0): Conv3DSimple(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "         (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       )\n",
       "       (relu): ReLU(inplace=True)\n",
       "     )\n",
       "   )\n",
       "   (layer2): Sequential(\n",
       "     (0): BasicBlock(\n",
       "       (conv1): Sequential(\n",
       "         (0): Conv3DSimple(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "         (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (2): ReLU(inplace=True)\n",
       "       )\n",
       "       (conv2): Sequential(\n",
       "         (0): Conv3DSimple(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "         (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       )\n",
       "       (relu): ReLU(inplace=True)\n",
       "       (downsample): Sequential(\n",
       "         (0): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "         (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       )\n",
       "     )\n",
       "     (1): BasicBlock(\n",
       "       (conv1): Sequential(\n",
       "         (0): Conv3DSimple(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "         (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (2): ReLU(inplace=True)\n",
       "       )\n",
       "       (conv2): Sequential(\n",
       "         (0): Conv3DSimple(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "         (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       )\n",
       "       (relu): ReLU(inplace=True)\n",
       "     )\n",
       "   )\n",
       "   (layer3): Sequential(\n",
       "     (0): BasicBlock(\n",
       "       (conv1): Sequential(\n",
       "         (0): Conv3DSimple(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "         (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (2): ReLU(inplace=True)\n",
       "       )\n",
       "       (conv2): Sequential(\n",
       "         (0): Conv3DSimple(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "         (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       )\n",
       "       (relu): ReLU(inplace=True)\n",
       "       (downsample): Sequential(\n",
       "         (0): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "         (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       )\n",
       "     )\n",
       "     (1): BasicBlock(\n",
       "       (conv1): Sequential(\n",
       "         (0): Conv3DSimple(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "         (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (2): ReLU(inplace=True)\n",
       "       )\n",
       "       (conv2): Sequential(\n",
       "         (0): Conv3DSimple(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "         (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       )\n",
       "       (relu): ReLU(inplace=True)\n",
       "     )\n",
       "   )\n",
       "   (layer4): Sequential(\n",
       "     (0): BasicBlock(\n",
       "       (conv1): Sequential(\n",
       "         (0): Conv3DSimple(256, 512, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "         (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (2): ReLU(inplace=True)\n",
       "       )\n",
       "       (conv2): Sequential(\n",
       "         (0): Conv3DSimple(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "         (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       )\n",
       "       (relu): ReLU(inplace=True)\n",
       "       (downsample): Sequential(\n",
       "         (0): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "         (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       )\n",
       "     )\n",
       "     (1): BasicBlock(\n",
       "       (conv1): Sequential(\n",
       "         (0): Conv3DSimple(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "         (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (2): ReLU(inplace=True)\n",
       "       )\n",
       "       (conv2): Sequential(\n",
       "         (0): Conv3DSimple(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "         (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       )\n",
       "       (relu): ReLU(inplace=True)\n",
       "     )\n",
       "   )\n",
       "   (avgpool): AdaptiveAvgPool3d(output_size=(1, 1, 1))\n",
       "   (fc): Linear(in_features=512, out_features=400, bias=True)\n",
       " ),\n",
       " BasicStem(\n",
       "   (0): Conv3d(3, 64, kernel_size=(3, 7, 7), stride=(1, 2, 2), padding=(1, 3, 3), bias=False)\n",
       "   (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (2): ReLU(inplace=True)\n",
       " ),\n",
       " Conv3d(3, 64, kernel_size=(3, 7, 7), stride=(1, 2, 2), padding=(1, 3, 3), bias=False),\n",
       " BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " ReLU(inplace=True),\n",
       " Sequential(\n",
       "   (0): BasicBlock(\n",
       "     (conv1): Sequential(\n",
       "       (0): Conv3DSimple(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "       (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (2): ReLU(inplace=True)\n",
       "     )\n",
       "     (conv2): Sequential(\n",
       "       (0): Conv3DSimple(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "       (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "     (relu): ReLU(inplace=True)\n",
       "   )\n",
       "   (1): BasicBlock(\n",
       "     (conv1): Sequential(\n",
       "       (0): Conv3DSimple(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "       (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (2): ReLU(inplace=True)\n",
       "     )\n",
       "     (conv2): Sequential(\n",
       "       (0): Conv3DSimple(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "       (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "     (relu): ReLU(inplace=True)\n",
       "   )\n",
       " ),\n",
       " BasicBlock(\n",
       "   (conv1): Sequential(\n",
       "     (0): Conv3DSimple(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "     (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (2): ReLU(inplace=True)\n",
       "   )\n",
       "   (conv2): Sequential(\n",
       "     (0): Conv3DSimple(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "     (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (relu): ReLU(inplace=True)\n",
       " ),\n",
       " Sequential(\n",
       "   (0): Conv3DSimple(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "   (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (2): ReLU(inplace=True)\n",
       " ),\n",
       " Conv3DSimple(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False),\n",
       " BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " ReLU(inplace=True),\n",
       " Sequential(\n",
       "   (0): Conv3DSimple(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "   (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       " ),\n",
       " Conv3DSimple(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False),\n",
       " BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " ReLU(inplace=True),\n",
       " BasicBlock(\n",
       "   (conv1): Sequential(\n",
       "     (0): Conv3DSimple(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "     (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (2): ReLU(inplace=True)\n",
       "   )\n",
       "   (conv2): Sequential(\n",
       "     (0): Conv3DSimple(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "     (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (relu): ReLU(inplace=True)\n",
       " ),\n",
       " Sequential(\n",
       "   (0): Conv3DSimple(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "   (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (2): ReLU(inplace=True)\n",
       " ),\n",
       " Conv3DSimple(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False),\n",
       " BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " ReLU(inplace=True),\n",
       " Sequential(\n",
       "   (0): Conv3DSimple(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "   (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       " ),\n",
       " Conv3DSimple(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False),\n",
       " BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " ReLU(inplace=True),\n",
       " Sequential(\n",
       "   (0): BasicBlock(\n",
       "     (conv1): Sequential(\n",
       "       (0): Conv3DSimple(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "       (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (2): ReLU(inplace=True)\n",
       "     )\n",
       "     (conv2): Sequential(\n",
       "       (0): Conv3DSimple(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "       (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "     (relu): ReLU(inplace=True)\n",
       "     (downsample): Sequential(\n",
       "       (0): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "       (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       "   (1): BasicBlock(\n",
       "     (conv1): Sequential(\n",
       "       (0): Conv3DSimple(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "       (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (2): ReLU(inplace=True)\n",
       "     )\n",
       "     (conv2): Sequential(\n",
       "       (0): Conv3DSimple(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "       (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "     (relu): ReLU(inplace=True)\n",
       "   )\n",
       " ),\n",
       " BasicBlock(\n",
       "   (conv1): Sequential(\n",
       "     (0): Conv3DSimple(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "     (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (2): ReLU(inplace=True)\n",
       "   )\n",
       "   (conv2): Sequential(\n",
       "     (0): Conv3DSimple(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "     (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (relu): ReLU(inplace=True)\n",
       "   (downsample): Sequential(\n",
       "     (0): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "     (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       " ),\n",
       " Sequential(\n",
       "   (0): Conv3DSimple(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "   (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (2): ReLU(inplace=True)\n",
       " ),\n",
       " Conv3DSimple(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False),\n",
       " BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " ReLU(inplace=True),\n",
       " Sequential(\n",
       "   (0): Conv3DSimple(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "   (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       " ),\n",
       " Conv3DSimple(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False),\n",
       " BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " ReLU(inplace=True),\n",
       " Sequential(\n",
       "   (0): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "   (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       " ),\n",
       " Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False),\n",
       " BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " BasicBlock(\n",
       "   (conv1): Sequential(\n",
       "     (0): Conv3DSimple(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "     (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (2): ReLU(inplace=True)\n",
       "   )\n",
       "   (conv2): Sequential(\n",
       "     (0): Conv3DSimple(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "     (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (relu): ReLU(inplace=True)\n",
       " ),\n",
       " Sequential(\n",
       "   (0): Conv3DSimple(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "   (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (2): ReLU(inplace=True)\n",
       " ),\n",
       " Conv3DSimple(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False),\n",
       " BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " ReLU(inplace=True),\n",
       " Sequential(\n",
       "   (0): Conv3DSimple(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "   (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       " ),\n",
       " Conv3DSimple(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False),\n",
       " BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " ReLU(inplace=True),\n",
       " Sequential(\n",
       "   (0): BasicBlock(\n",
       "     (conv1): Sequential(\n",
       "       (0): Conv3DSimple(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "       (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (2): ReLU(inplace=True)\n",
       "     )\n",
       "     (conv2): Sequential(\n",
       "       (0): Conv3DSimple(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "       (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "     (relu): ReLU(inplace=True)\n",
       "     (downsample): Sequential(\n",
       "       (0): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "       (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       "   (1): BasicBlock(\n",
       "     (conv1): Sequential(\n",
       "       (0): Conv3DSimple(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "       (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (2): ReLU(inplace=True)\n",
       "     )\n",
       "     (conv2): Sequential(\n",
       "       (0): Conv3DSimple(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "       (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "     (relu): ReLU(inplace=True)\n",
       "   )\n",
       " ),\n",
       " BasicBlock(\n",
       "   (conv1): Sequential(\n",
       "     (0): Conv3DSimple(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "     (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (2): ReLU(inplace=True)\n",
       "   )\n",
       "   (conv2): Sequential(\n",
       "     (0): Conv3DSimple(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "     (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (relu): ReLU(inplace=True)\n",
       "   (downsample): Sequential(\n",
       "     (0): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "     (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       " ),\n",
       " Sequential(\n",
       "   (0): Conv3DSimple(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "   (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (2): ReLU(inplace=True)\n",
       " ),\n",
       " Conv3DSimple(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False),\n",
       " BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " ReLU(inplace=True),\n",
       " Sequential(\n",
       "   (0): Conv3DSimple(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "   (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       " ),\n",
       " Conv3DSimple(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False),\n",
       " BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " ReLU(inplace=True),\n",
       " Sequential(\n",
       "   (0): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "   (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       " ),\n",
       " Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False),\n",
       " BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " BasicBlock(\n",
       "   (conv1): Sequential(\n",
       "     (0): Conv3DSimple(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "     (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (2): ReLU(inplace=True)\n",
       "   )\n",
       "   (conv2): Sequential(\n",
       "     (0): Conv3DSimple(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "     (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (relu): ReLU(inplace=True)\n",
       " ),\n",
       " Sequential(\n",
       "   (0): Conv3DSimple(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "   (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (2): ReLU(inplace=True)\n",
       " ),\n",
       " Conv3DSimple(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False),\n",
       " BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " ReLU(inplace=True),\n",
       " Sequential(\n",
       "   (0): Conv3DSimple(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "   (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       " ),\n",
       " Conv3DSimple(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False),\n",
       " BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " ReLU(inplace=True),\n",
       " Sequential(\n",
       "   (0): BasicBlock(\n",
       "     (conv1): Sequential(\n",
       "       (0): Conv3DSimple(256, 512, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "       (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (2): ReLU(inplace=True)\n",
       "     )\n",
       "     (conv2): Sequential(\n",
       "       (0): Conv3DSimple(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "       (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "     (relu): ReLU(inplace=True)\n",
       "     (downsample): Sequential(\n",
       "       (0): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "       (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       "   (1): BasicBlock(\n",
       "     (conv1): Sequential(\n",
       "       (0): Conv3DSimple(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "       (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (2): ReLU(inplace=True)\n",
       "     )\n",
       "     (conv2): Sequential(\n",
       "       (0): Conv3DSimple(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "       (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "     (relu): ReLU(inplace=True)\n",
       "   )\n",
       " ),\n",
       " BasicBlock(\n",
       "   (conv1): Sequential(\n",
       "     (0): Conv3DSimple(256, 512, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "     (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (2): ReLU(inplace=True)\n",
       "   )\n",
       "   (conv2): Sequential(\n",
       "     (0): Conv3DSimple(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "     (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (relu): ReLU(inplace=True)\n",
       "   (downsample): Sequential(\n",
       "     (0): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "     (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       " ),\n",
       " Sequential(\n",
       "   (0): Conv3DSimple(256, 512, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "   (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (2): ReLU(inplace=True)\n",
       " ),\n",
       " Conv3DSimple(256, 512, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False),\n",
       " BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " ReLU(inplace=True),\n",
       " Sequential(\n",
       "   (0): Conv3DSimple(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "   (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       " ),\n",
       " Conv3DSimple(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False),\n",
       " BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " ReLU(inplace=True),\n",
       " Sequential(\n",
       "   (0): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "   (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       " ),\n",
       " Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False),\n",
       " BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " BasicBlock(\n",
       "   (conv1): Sequential(\n",
       "     (0): Conv3DSimple(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "     (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (2): ReLU(inplace=True)\n",
       "   )\n",
       "   (conv2): Sequential(\n",
       "     (0): Conv3DSimple(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "     (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (relu): ReLU(inplace=True)\n",
       " ),\n",
       " Sequential(\n",
       "   (0): Conv3DSimple(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "   (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (2): ReLU(inplace=True)\n",
       " ),\n",
       " Conv3DSimple(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False),\n",
       " BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " ReLU(inplace=True),\n",
       " Sequential(\n",
       "   (0): Conv3DSimple(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "   (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       " ),\n",
       " Conv3DSimple(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False),\n",
       " BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " ReLU(inplace=True),\n",
       " AdaptiveAvgPool3d(output_size=(1, 1, 1)),\n",
       " Linear(in_features=512, out_features=400, bias=True)]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = list(modules[0].modules())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(model[0].modules()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "If size is a sequence, it should have 1 or 2 values",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[123], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m preprocess \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mCompose([\n\u001b[1;32m----> 2\u001b[0m     \u001b[43mtransforms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mResize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m171\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m      3\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mToTensor(),\n\u001b[0;32m      4\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mNormalize(mean\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0.43216\u001b[39m, \u001b[38;5;241m0.394666\u001b[39m, \u001b[38;5;241m0.37645\u001b[39m],\n\u001b[0;32m      5\u001b[0m                          std\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0.22803\u001b[39m, \u001b[38;5;241m0.22145\u001b[39m, \u001b[38;5;241m0.216989\u001b[39m])\n\u001b[0;32m      6\u001b[0m ])\n",
      "File \u001b[1;32mc:\\Users\\Asus\\Desktop\\Phosphene.AI\\sizeinvar_timesformer\\Lib\\site-packages\\torchvision\\transforms\\transforms.py:336\u001b[0m, in \u001b[0;36mResize.__init__\u001b[1;34m(self, size, interpolation, max_size, antialias)\u001b[0m\n\u001b[0;32m    334\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSize should be int or sequence. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(size)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    335\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(size, Sequence) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(size) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m):\n\u001b[1;32m--> 336\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf size is a sequence, it should have 1 or 2 values\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    337\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m=\u001b[39m size\n\u001b[0;32m    338\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_size \u001b[38;5;241m=\u001b[39m max_size\n",
      "\u001b[1;31mValueError\u001b[0m: If size is a sequence, it should have 1 or 2 values"
     ]
    }
   ],
   "source": [
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((128, 171)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.43216, 0.394666, 0.37645],\n",
    "                         std=[0.22803, 0.22145, 0.216989])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input and output must have the same number of spatial dimensions, but got input with spatial dimensions of [3, 224, 224] and output size of [128, 171]. Please provide input tensor in (N, C, d1, d2, ...,dK) format and output size in (o1, o2, ...,oK) format.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[124], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m out \u001b[38;5;241m=\u001b[39m pretrained_sequential(\u001b[43mpreprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpermute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m4\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\Asus\\Desktop\\Phosphene.AI\\sizeinvar_timesformer\\Lib\\site-packages\\torchvision\\transforms\\transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[1;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[1;32mc:\\Users\\Asus\\Desktop\\Phosphene.AI\\sizeinvar_timesformer\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Asus\\Desktop\\Phosphene.AI\\sizeinvar_timesformer\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Asus\\Desktop\\Phosphene.AI\\sizeinvar_timesformer\\Lib\\site-packages\\torchvision\\transforms\\transforms.py:354\u001b[0m, in \u001b[0;36mResize.forward\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[0;32m    347\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m    349\u001b[0m \u001b[38;5;124;03m        img (PIL Image or Tensor): Image to be scaled.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    352\u001b[0m \u001b[38;5;124;03m        PIL Image or Tensor: Rescaled image.\u001b[39;00m\n\u001b[0;32m    353\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 354\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpolation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mantialias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Asus\\Desktop\\Phosphene.AI\\sizeinvar_timesformer\\Lib\\site-packages\\torchvision\\transforms\\functional.py:469\u001b[0m, in \u001b[0;36mresize\u001b[1;34m(img, size, interpolation, max_size, antialias)\u001b[0m\n\u001b[0;32m    466\u001b[0m     pil_interpolation \u001b[38;5;241m=\u001b[39m pil_modes_mapping[interpolation]\n\u001b[0;32m    467\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F_pil\u001b[38;5;241m.\u001b[39mresize(img, size\u001b[38;5;241m=\u001b[39moutput_size, interpolation\u001b[38;5;241m=\u001b[39mpil_interpolation)\n\u001b[1;32m--> 469\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF_t\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mantialias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mantialias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Asus\\Desktop\\Phosphene.AI\\sizeinvar_timesformer\\Lib\\site-packages\\torchvision\\transforms\\_functional_tensor.py:465\u001b[0m, in \u001b[0;36mresize\u001b[1;34m(img, size, interpolation, antialias)\u001b[0m\n\u001b[0;32m    462\u001b[0m \u001b[38;5;66;03m# Define align_corners to avoid warnings\u001b[39;00m\n\u001b[0;32m    463\u001b[0m align_corners \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m interpolation \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbilinear\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbicubic\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 465\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43minterpolate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterpolation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malign_corners\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malign_corners\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mantialias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mantialias\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    467\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m interpolation \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbicubic\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m out_dtype \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39muint8:\n\u001b[0;32m    468\u001b[0m     img \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mclamp(\u001b[38;5;28mmin\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mmax\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m255\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Asus\\Desktop\\Phosphene.AI\\sizeinvar_timesformer\\Lib\\site-packages\\torch\\nn\\functional.py:3934\u001b[0m, in \u001b[0;36minterpolate\u001b[1;34m(input, size, scale_factor, mode, align_corners, recompute_scale_factor, antialias)\u001b[0m\n\u001b[0;32m   3932\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(size, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[0;32m   3933\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(size) \u001b[38;5;241m!=\u001b[39m dim:\n\u001b[1;32m-> 3934\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   3935\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput and output must have the same number of spatial dimensions, but got \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3936\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput with spatial dimensions of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m:])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and output size of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msize\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3937\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease provide input tensor in (N, C, d1, d2, ...,dK) format and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3938\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput size in (o1, o2, ...,oK) format.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3939\u001b[0m         )\n\u001b[0;32m   3940\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_scripting():\n\u001b[0;32m   3941\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(_is_integer(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m size):\n",
      "\u001b[1;31mValueError\u001b[0m: Input and output must have the same number of spatial dimensions, but got input with spatial dimensions of [3, 224, 224] and output size of [128, 171]. Please provide input tensor in (N, C, d1, d2, ...,dK) format and output size in (o1, o2, ...,oK) format."
     ]
    }
   ],
   "source": [
    "out = pretrained_sequential(preprocess(video.permute(0,2,1,3,4)).permute(0,2,1,3,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = out.reshape((1,20,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = out.permute(1,2,0).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1604d99cb10>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(out,cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VideoResNet(\n",
       "  (stem): BasicStem(\n",
       "    (0): Conv3d(3, 64, kernel_size=(3, 7, 7), stride=(1, 2, 2), padding=(1, 3, 3), bias=False)\n",
       "    (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "  )\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv3DSimple(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv3DSimple(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv3DSimple(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv3DSimple(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv3DSimple(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv3DSimple(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "        (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv3DSimple(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv3DSimple(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv3DSimple(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv3DSimple(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "        (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv3DSimple(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv3DSimple(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv3DSimple(256, 512, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv3DSimple(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "        (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv3DSimple(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv3DSimple(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool3d(output_size=(1, 1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=400, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modules[:2][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (module0): VideoResNet(\n",
       "    (stem): BasicStem(\n",
       "      (0): Conv3d(3, 64, kernel_size=(3, 7, 7), stride=(1, 2, 2), padding=(1, 3, 3), bias=False)\n",
       "      (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Sequential(\n",
       "          (0): Conv3DSimple(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv2): Sequential(\n",
       "          (0): Conv3DSimple(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Sequential(\n",
       "          (0): Conv3DSimple(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv2): Sequential(\n",
       "          (0): Conv3DSimple(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Sequential(\n",
       "          (0): Conv3DSimple(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "          (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv2): Sequential(\n",
       "          (0): Conv3DSimple(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "          (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Sequential(\n",
       "          (0): Conv3DSimple(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv2): Sequential(\n",
       "          (0): Conv3DSimple(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Sequential(\n",
       "          (0): Conv3DSimple(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "          (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv2): Sequential(\n",
       "          (0): Conv3DSimple(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "          (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Sequential(\n",
       "          (0): Conv3DSimple(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv2): Sequential(\n",
       "          (0): Conv3DSimple(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Sequential(\n",
       "          (0): Conv3DSimple(256, 512, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "          (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv2): Sequential(\n",
       "          (0): Conv3DSimple(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "          (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Sequential(\n",
       "          (0): Conv3DSimple(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv2): Sequential(\n",
       "          (0): Conv3DSimple(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool3d(output_size=(1, 1, 1))\n",
       "    (fc): Linear(in_features=512, out_features=400, bias=True)\n",
       "  )\n",
       "  (module1): BasicStem(\n",
       "    (0): Conv3d(3, 64, kernel_size=(3, 7, 7), stride=(1, 2, 2), padding=(1, 3, 3), bias=False)\n",
       "    (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "  )\n",
       "  (module2): Conv3d(3, 64, kernel_size=(3, 7, 7), stride=(1, 2, 2), padding=(1, 3, 3), bias=False)\n",
       "  (module3): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (module4): ReLU(inplace=True)\n",
       "  (module5): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv3DSimple(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv3DSimple(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv3DSimple(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv3DSimple(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (module6): BasicBlock(\n",
       "    (conv1): Sequential(\n",
       "      (0): Conv3DSimple(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (conv2): Sequential(\n",
       "      (0): Conv3DSimple(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (relu): ReLU(inplace=True)\n",
       "  )\n",
       "  (module7): Sequential(\n",
       "    (0): Conv3DSimple(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "    (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "  )\n",
       "  (module8): Conv3DSimple(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "  (module9): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (module10): ReLU(inplace=True)\n",
       "  (module11): Sequential(\n",
       "    (0): Conv3DSimple(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "    (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (module12): Conv3DSimple(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "  (module13): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (module14): ReLU(inplace=True)\n",
       "  (module15): BasicBlock(\n",
       "    (conv1): Sequential(\n",
       "      (0): Conv3DSimple(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (conv2): Sequential(\n",
       "      (0): Conv3DSimple(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (relu): ReLU(inplace=True)\n",
       "  )\n",
       "  (module16): Sequential(\n",
       "    (0): Conv3DSimple(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "    (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "  )\n",
       "  (module17): Conv3DSimple(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "  (module18): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (module19): ReLU(inplace=True)\n",
       "  (module20): Sequential(\n",
       "    (0): Conv3DSimple(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "    (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (module21): Conv3DSimple(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "  (module22): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (module23): ReLU(inplace=True)\n",
       "  (module24): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv3DSimple(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv3DSimple(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "        (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv3DSimple(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv3DSimple(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (module25): BasicBlock(\n",
       "    (conv1): Sequential(\n",
       "      (0): Conv3DSimple(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "      (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (conv2): Sequential(\n",
       "      (0): Conv3DSimple(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (downsample): Sequential(\n",
       "      (0): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "      (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (module26): Sequential(\n",
       "    (0): Conv3DSimple(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "    (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "  )\n",
       "  (module27): Conv3DSimple(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "  (module28): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (module29): ReLU(inplace=True)\n",
       "  (module30): Sequential(\n",
       "    (0): Conv3DSimple(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "    (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (module31): Conv3DSimple(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "  (module32): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (module33): ReLU(inplace=True)\n",
       "  (module34): Sequential(\n",
       "    (0): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "    (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (module35): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "  (module36): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (module37): BasicBlock(\n",
       "    (conv1): Sequential(\n",
       "      (0): Conv3DSimple(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (conv2): Sequential(\n",
       "      (0): Conv3DSimple(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (relu): ReLU(inplace=True)\n",
       "  )\n",
       "  (module38): Sequential(\n",
       "    (0): Conv3DSimple(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "    (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "  )\n",
       "  (module39): Conv3DSimple(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "  (module40): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (module41): ReLU(inplace=True)\n",
       "  (module42): Sequential(\n",
       "    (0): Conv3DSimple(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "    (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (module43): Conv3DSimple(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "  (module44): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (module45): ReLU(inplace=True)\n",
       "  (module46): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv3DSimple(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv3DSimple(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "        (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv3DSimple(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv3DSimple(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (module47): BasicBlock(\n",
       "    (conv1): Sequential(\n",
       "      (0): Conv3DSimple(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "      (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (conv2): Sequential(\n",
       "      (0): Conv3DSimple(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (downsample): Sequential(\n",
       "      (0): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "      (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (module48): Sequential(\n",
       "    (0): Conv3DSimple(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "    (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "  )\n",
       "  (module49): Conv3DSimple(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "  (module50): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (module51): ReLU(inplace=True)\n",
       "  (module52): Sequential(\n",
       "    (0): Conv3DSimple(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "    (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (module53): Conv3DSimple(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "  (module54): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (module55): ReLU(inplace=True)\n",
       "  (module56): Sequential(\n",
       "    (0): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "    (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (module57): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "  (module58): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (module59): BasicBlock(\n",
       "    (conv1): Sequential(\n",
       "      (0): Conv3DSimple(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (conv2): Sequential(\n",
       "      (0): Conv3DSimple(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (relu): ReLU(inplace=True)\n",
       "  )\n",
       "  (module60): Sequential(\n",
       "    (0): Conv3DSimple(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "    (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "  )\n",
       "  (module61): Conv3DSimple(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "  (module62): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (module63): ReLU(inplace=True)\n",
       "  (module64): Sequential(\n",
       "    (0): Conv3DSimple(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "    (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (module65): Conv3DSimple(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "  (module66): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (module67): ReLU(inplace=True)\n",
       "  (module68): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv3DSimple(256, 512, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv3DSimple(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "        (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv3DSimple(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv3DSimple(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (module69): BasicBlock(\n",
       "    (conv1): Sequential(\n",
       "      (0): Conv3DSimple(256, 512, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "      (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (conv2): Sequential(\n",
       "      (0): Conv3DSimple(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (downsample): Sequential(\n",
       "      (0): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "      (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (module70): Sequential(\n",
       "    (0): Conv3DSimple(256, 512, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "    (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "  )\n",
       "  (module71): Conv3DSimple(256, 512, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "  (module72): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (module73): ReLU(inplace=True)\n",
       "  (module74): Sequential(\n",
       "    (0): Conv3DSimple(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "    (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (module75): Conv3DSimple(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "  (module76): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (module77): ReLU(inplace=True)\n",
       "  (module78): Sequential(\n",
       "    (0): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "    (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (module79): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "  (module80): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (module81): BasicBlock(\n",
       "    (conv1): Sequential(\n",
       "      (0): Conv3DSimple(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (conv2): Sequential(\n",
       "      (0): Conv3DSimple(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (relu): ReLU(inplace=True)\n",
       "  )\n",
       "  (module82): Sequential(\n",
       "    (0): Conv3DSimple(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "    (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "  )\n",
       "  (module83): Conv3DSimple(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "  (module84): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (module85): ReLU(inplace=True)\n",
       "  (module86): Sequential(\n",
       "    (0): Conv3DSimple(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "    (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (module87): Conv3DSimple(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "  (module88): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (module89): ReLU(inplace=True)\n",
       "  (module90): AdaptiveAvgPool3d(output_size=(1, 1, 1))\n",
       "  (module91): Linear(in_features=512, out_features=400, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_sequential[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 20, 1)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "conv3d() received an invalid combination of arguments - got (NoneType, Parameter, Parameter, tuple, tuple, tuple, int), but expected one of:\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, tuple of ints padding, tuple of ints dilation, int groups)\n      didn't match because some of the arguments have invalid types: (!NoneType!, !Parameter!, !Parameter!, !tuple of (int, int, int)!, !tuple of (int, int, int)!, !tuple of (int, int, int)!, int)\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, str padding, tuple of ints dilation, int groups)\n      didn't match because some of the arguments have invalid types: (!NoneType!, !Parameter!, !Parameter!, !tuple of (int, int, int)!, !tuple of (int, int, int)!, !tuple of (int, int, int)!, int)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[139], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m x \u001b[38;5;241m=\u001b[39m video\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, module \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mnamed_children():\n\u001b[1;32m----> 5\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m layers:\n\u001b[0;32m      7\u001b[0m         features\u001b[38;5;241m.\u001b[39mappend(x)\n",
      "File \u001b[1;32mc:\\Users\\Asus\\Desktop\\Phosphene.AI\\sizeinvar_timesformer\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Asus\\Desktop\\Phosphene.AI\\sizeinvar_timesformer\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Asus\\Desktop\\Phosphene.AI\\sizeinvar_timesformer\\Lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Asus\\Desktop\\Phosphene.AI\\sizeinvar_timesformer\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Asus\\Desktop\\Phosphene.AI\\sizeinvar_timesformer\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Asus\\Desktop\\Phosphene.AI\\sizeinvar_timesformer\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:610\u001b[0m, in \u001b[0;36mConv3d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    609\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 610\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Asus\\Desktop\\Phosphene.AI\\sizeinvar_timesformer\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:605\u001b[0m, in \u001b[0;36mConv3d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    593\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    594\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv3d(\n\u001b[0;32m    595\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[0;32m    596\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    603\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[0;32m    604\u001b[0m     )\n\u001b[1;32m--> 605\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv3d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    606\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[0;32m    607\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: conv3d() received an invalid combination of arguments - got (NoneType, Parameter, Parameter, tuple, tuple, tuple, int), but expected one of:\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, tuple of ints padding, tuple of ints dilation, int groups)\n      didn't match because some of the arguments have invalid types: (!NoneType!, !Parameter!, !Parameter!, !tuple of (int, int, int)!, !tuple of (int, int, int)!, !tuple of (int, int, int)!, int)\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, str padding, tuple of ints dilation, int groups)\n      didn't match because some of the arguments have invalid types: (!NoneType!, !Parameter!, !Parameter!, !tuple of (int, int, int)!, !tuple of (int, int, int)!, !tuple of (int, int, int)!, int)\n"
     ]
    }
   ],
   "source": [
    "features = []\n",
    "layers = ['layer1', 'layer2', 'layer3', 'layer4', 'layer5']\n",
    "x = video\n",
    "for name, module in model.named_children():\n",
    "    x = module(x)\n",
    "    if name in layers:\n",
    "        features.append(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoFeatureExtractor(nn.Module):\n",
    "\n",
    "    def __init__(self,):\n",
    "        self.resnet = r3d_18()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "id": "67tM767LiB0X"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UNet, self).__init__()\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv3d(3, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv3d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool3d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Conv3d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv3d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose3d(64, 1, kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.encoder(x)\n",
    "        x = self.decoder(x1)\n",
    "        x = torch.sigmoid(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "model = UNet()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = nn.Sequential(\n",
    "            nn.Conv3d(3, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv3d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool3d(kernel_size=2, stride=2)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = nn.Sequential(\n",
    "            nn.Conv3d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv3d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose3d(64, 1, kernel_size=2, stride=2)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "o = encoder(videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[[0.4748, 0.4728, 0.4745,  ..., 0.4716, 0.4730, 0.4710],\n",
       "           [0.4781, 0.4754, 0.4772,  ..., 0.4744, 0.4784, 0.4747],\n",
       "           [0.4731, 0.4739, 0.4747,  ..., 0.4714, 0.4736, 0.4695],\n",
       "           ...,\n",
       "           [0.4780, 0.4743, 0.4788,  ..., 0.4757, 0.4799, 0.4740],\n",
       "           [0.4721, 0.4727, 0.4740,  ..., 0.4717, 0.4737, 0.4704],\n",
       "           [0.4800, 0.4753, 0.4804,  ..., 0.4766, 0.4798, 0.4754]],\n",
       "\n",
       "          [[0.4788, 0.4702, 0.4788,  ..., 0.4673, 0.4767, 0.4663],\n",
       "           [0.4789, 0.4778, 0.4782,  ..., 0.4778, 0.4789, 0.4780],\n",
       "           [0.4818, 0.4690, 0.4823,  ..., 0.4662, 0.4775, 0.4662],\n",
       "           ...,\n",
       "           [0.4780, 0.4774, 0.4758,  ..., 0.4766, 0.4767, 0.4766],\n",
       "           [0.4783, 0.4694, 0.4774,  ..., 0.4672, 0.4770, 0.4684],\n",
       "           [0.4777, 0.4777, 0.4773,  ..., 0.4787, 0.4776, 0.4784]],\n",
       "\n",
       "          [[0.4756, 0.4720, 0.4733,  ..., 0.4719, 0.4732, 0.4717],\n",
       "           [0.4788, 0.4774, 0.4814,  ..., 0.4737, 0.4800, 0.4749],\n",
       "           [0.4750, 0.4726, 0.4733,  ..., 0.4734, 0.4736, 0.4720],\n",
       "           ...,\n",
       "           [0.4782, 0.4737, 0.4803,  ..., 0.4740, 0.4813, 0.4727],\n",
       "           [0.4725, 0.4707, 0.4748,  ..., 0.4738, 0.4742, 0.4729],\n",
       "           [0.4809, 0.4735, 0.4809,  ..., 0.4746, 0.4806, 0.4750]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[0.4803, 0.4698, 0.4796,  ..., 0.4672, 0.4761, 0.4678],\n",
       "           [0.4788, 0.4779, 0.4766,  ..., 0.4763, 0.4773, 0.4779],\n",
       "           [0.4819, 0.4688, 0.4841,  ..., 0.4659, 0.4775, 0.4681],\n",
       "           ...,\n",
       "           [0.4785, 0.4801, 0.4757,  ..., 0.4809, 0.4761, 0.4788],\n",
       "           [0.4779, 0.4699, 0.4796,  ..., 0.4669, 0.4785, 0.4668],\n",
       "           [0.4786, 0.4797, 0.4794,  ..., 0.4816, 0.4782, 0.4796]],\n",
       "\n",
       "          [[0.4742, 0.4729, 0.4714,  ..., 0.4749, 0.4715, 0.4739],\n",
       "           [0.4799, 0.4768, 0.4850,  ..., 0.4768, 0.4827, 0.4768],\n",
       "           [0.4735, 0.4727, 0.4704,  ..., 0.4764, 0.4702, 0.4760],\n",
       "           ...,\n",
       "           [0.4806, 0.4759, 0.4828,  ..., 0.4748, 0.4828, 0.4741],\n",
       "           [0.4709, 0.4717, 0.4711,  ..., 0.4745, 0.4707, 0.4747],\n",
       "           [0.4809, 0.4742, 0.4794,  ..., 0.4739, 0.4807, 0.4747]],\n",
       "\n",
       "          [[0.4786, 0.4695, 0.4774,  ..., 0.4682, 0.4766, 0.4683],\n",
       "           [0.4775, 0.4770, 0.4760,  ..., 0.4757, 0.4760, 0.4764],\n",
       "           [0.4797, 0.4695, 0.4812,  ..., 0.4677, 0.4785, 0.4686],\n",
       "           ...,\n",
       "           [0.4778, 0.4790, 0.4759,  ..., 0.4783, 0.4767, 0.4784],\n",
       "           [0.4776, 0.4702, 0.4796,  ..., 0.4674, 0.4800, 0.4667],\n",
       "           [0.4790, 0.4796, 0.4787,  ..., 0.4791, 0.4788, 0.4787]]]]],\n",
       "       grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sigmoid(decoder(o))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H3WfVuNdiqwZ",
    "outputId": "9faf6a8b-457a-449d-bcdf-fb87a73b73c5"
   },
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[[0.4947, 0.5037, 0.4958,  ..., 0.5023, 0.4947, 0.5026],\n",
       "           [0.5003, 0.5025, 0.5011,  ..., 0.5030, 0.5022, 0.5054],\n",
       "           [0.4938, 0.5021, 0.4965,  ..., 0.5033, 0.4939, 0.5030],\n",
       "           ...,\n",
       "           [0.4966, 0.5042, 0.4967,  ..., 0.5042, 0.4999, 0.5040],\n",
       "           [0.4931, 0.5037, 0.4938,  ..., 0.5043, 0.4928, 0.5048],\n",
       "           [0.4955, 0.5052, 0.4941,  ..., 0.5048, 0.4987, 0.5033]],\n",
       "\n",
       "          [[0.5056, 0.4909, 0.5054,  ..., 0.4914, 0.5062, 0.4924],\n",
       "           [0.4939, 0.4981, 0.4911,  ..., 0.4994, 0.4932, 0.4977],\n",
       "           [0.5071, 0.4900, 0.5052,  ..., 0.4894, 0.5051, 0.4917],\n",
       "           ...,\n",
       "           [0.4946, 0.4997, 0.4929,  ..., 0.5002, 0.4929, 0.4954],\n",
       "           [0.5074, 0.4906, 0.5071,  ..., 0.4877, 0.5047, 0.4894],\n",
       "           [0.4963, 0.4993, 0.4960,  ..., 0.5001, 0.4953, 0.4950]],\n",
       "\n",
       "          [[0.4949, 0.5026, 0.4969,  ..., 0.5025, 0.4955, 0.5033],\n",
       "           [0.4984, 0.5025, 0.4977,  ..., 0.5003, 0.5014, 0.5031],\n",
       "           [0.4943, 0.5024, 0.4972,  ..., 0.5047, 0.4948, 0.5047],\n",
       "           ...,\n",
       "           [0.4955, 0.5054, 0.4932,  ..., 0.5035, 0.4986, 0.5024],\n",
       "           [0.4958, 0.5030, 0.4958,  ..., 0.5034, 0.4947, 0.5059],\n",
       "           [0.4946, 0.5053, 0.4936,  ..., 0.5054, 0.4982, 0.5041]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[0.5074, 0.4918, 0.5063,  ..., 0.4901, 0.5056, 0.4920],\n",
       "           [0.4954, 0.4986, 0.4942,  ..., 0.4997, 0.4949, 0.4986],\n",
       "           [0.5072, 0.4913, 0.5060,  ..., 0.4884, 0.5053, 0.4913],\n",
       "           ...,\n",
       "           [0.4967, 0.4993, 0.4973,  ..., 0.5017, 0.4940, 0.4974],\n",
       "           [0.5076, 0.4899, 0.5082,  ..., 0.4874, 0.5074, 0.4904],\n",
       "           [0.4961, 0.4995, 0.4980,  ..., 0.5016, 0.4957, 0.4978]],\n",
       "\n",
       "          [[0.4964, 0.5031, 0.4959,  ..., 0.5038, 0.4954, 0.5041],\n",
       "           [0.4971, 0.4997, 0.4972,  ..., 0.4990, 0.4999, 0.5011],\n",
       "           [0.4966, 0.5019, 0.4966,  ..., 0.5053, 0.4950, 0.5062],\n",
       "           ...,\n",
       "           [0.4967, 0.5011, 0.4976,  ..., 0.5000, 0.5001, 0.5007],\n",
       "           [0.4976, 0.5021, 0.4973,  ..., 0.5035, 0.4945, 0.5049],\n",
       "           [0.4963, 0.5026, 0.4973,  ..., 0.5030, 0.4996, 0.5031]],\n",
       "\n",
       "          [[0.5064, 0.4908, 0.5057,  ..., 0.4903, 0.5057, 0.4917],\n",
       "           [0.4963, 0.4967, 0.4968,  ..., 0.4967, 0.4956, 0.4967],\n",
       "           [0.5063, 0.4914, 0.5050,  ..., 0.4901, 0.5052, 0.4921],\n",
       "           ...,\n",
       "           [0.4962, 0.4983, 0.4979,  ..., 0.4982, 0.4937, 0.4982],\n",
       "           [0.5064, 0.4917, 0.5065,  ..., 0.4907, 0.5072, 0.4924],\n",
       "           [0.4956, 0.4986, 0.4970,  ..., 0.4997, 0.4951, 0.4985]]]]],\n",
       "       device='cuda:0', grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(video.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "NodXVbw2jDu3"
   },
   "outputs": [],
   "source": [
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sEnSzbAUkPO9",
    "outputId": "7cf7e58c-4b44-4f46-9f76-ce4eb5d53b63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.UNet'>\n",
      "['T_destination', '__annotations__', '__call__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattr__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_apply', '_backward_hooks', '_backward_pre_hooks', '_buffers', '_call_impl', '_compiled_call_impl', '_forward_hooks', '_forward_hooks_always_called', '_forward_hooks_with_kwargs', '_forward_pre_hooks', '_forward_pre_hooks_with_kwargs', '_get_backward_hooks', '_get_backward_pre_hooks', '_get_name', '_is_full_backward_hook', '_load_from_state_dict', '_load_state_dict_post_hooks', '_load_state_dict_pre_hooks', '_maybe_warn_non_full_backward_hook', '_modules', '_named_members', '_non_persistent_buffers_set', '_parameters', '_register_load_state_dict_pre_hook', '_register_state_dict_hook', '_replicate_for_data_parallel', '_save_to_state_dict', '_slow_forward', '_state_dict_hooks', '_state_dict_pre_hooks', '_version', '_wrapped_call_impl', 'add_module', 'apply', 'bfloat16', 'buffers', 'call_super_init', 'children', 'compile', 'cpu', 'cuda', 'decoder', 'double', 'dump_patches', 'encoder', 'eval', 'extra_repr', 'float', 'forward', 'get_buffer', 'get_extra_state', 'get_parameter', 'get_submodule', 'half', 'ipu', 'load_state_dict', 'modules', 'named_buffers', 'named_children', 'named_modules', 'named_parameters', 'parameters', 'register_backward_hook', 'register_buffer', 'register_forward_hook', 'register_forward_pre_hook', 'register_full_backward_hook', 'register_full_backward_pre_hook', 'register_load_state_dict_post_hook', 'register_module', 'register_parameter', 'register_state_dict_pre_hook', 'requires_grad_', 'set_extra_state', 'share_memory', 'state_dict', 'to', 'to_empty', 'train', 'training', 'type', 'xpu', 'zero_grad']\n"
     ]
    }
   ],
   "source": [
    "print(type(model))\n",
    "print(dir(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coefficient(y_true,y_pred):\n",
    "    smooth = 1e-6\n",
    "    intersection = torch.sum(y_true*y_pred)\n",
    "    union = torch.sum(y_true) + torch.sum(y_pred)\n",
    "    dice = (2. * intersection + smooth)/(union+smooth)\n",
    "    return dice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UIjiT5SMjb8O",
    "outputId": "827e717f-c85d-474a-e5d7-cc0278eeeade"
   },
   "outputs": [],
   "source": [
    "for epoch in range(5):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    similarity_index = 0.0\n",
    "    total_samples = 0\n",
    "    \n",
    "    for batch_idx, (videos, masks) in enumerate(train_loader):\n",
    "        print(f\"Epochs : {epoch+1}\")\n",
    "        videos, masks = videos.to(device), masks.to(device)\n",
    "        print(f\"Batch {batch_idx+1}/{len(train_loader)}\")\n",
    "        print(f\"Video shape: {videos.shape}\")\n",
    "        print(f\"Mask shape: {masks.shape}\")\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(videos)\n",
    "        print(f\"Output shape: {outputs.shape}\")\n",
    "\n",
    "        loss = criterion(outputs, masks)\n",
    "        print(f\"Loss for batch {batch_idx+1}: {loss.item():.4f}\")\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        batch_size = videos.size(0)\n",
    "        total_samples += batch_size\n",
    "        \n",
    "        #similarity index \n",
    "        outputs_binary = torch.sigmoid(outputs) > 0.5\n",
    "        similarity_index += dice_coefficient(masks, outputs_binary).item() * batch_size\n",
    "\n",
    "    avg_loss = epoch_loss / len(train_loader)\n",
    "    avg_similarity_index = similarity_index / total_samples\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{5}], Average Loss: {avg_loss:.4f}, Similarity Index: {avg_similarity_index:.4f}')\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rn-ot7YfpCaG",
    "outputId": "68b2bbdf-fbc1-4e94-d7cc-4d6ff65db504"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "val_loss = 0.0\n",
    "val_iou = 0.0\n",
    "total_val_samples = 0\n",
    "\n",
    "        \n",
    "with torch.no_grad():\n",
    "    for batch_idx, (videos, masks) in enumerate(val_loader):\n",
    "        videos, masks = videos.to(device), masks.to(device)\n",
    "        outputs = model(videos)\n",
    "        loss = criterion(outputs, masks)\n",
    "        val_loss += loss.item()\n",
    "            \n",
    "        \n",
    "            \n",
    "        total_val_samples += videos.size(0)\n",
    "    \n",
    "avg_val_loss = val_loss / len(val_loader)\n",
    "    \n",
    "print(f'Validation Loss: {avg_val_loss:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = epoch\n",
    "PATH = \"model.pt\"\n",
    "LOSS = val_loss\n",
    "\n",
    "torch.save({\n",
    "            'epoch': EPOCH,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': LOSS,\n",
    "            }, PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "id": "vXUEA2FRjXeM",
    "outputId": "b180bd0e-c1ce-435c-89d9-aca67f38d8cc"
   },
   "outputs": [],
   "source": [
    "for videos, masks in train_loader:\n",
    "      videos, masks = videos.to(device), masks.to(device)\n",
    "      break\n",
    "plt.imshow(transforms.ToPILImage()(outputs[0,:,3,:,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "id": "KzdOuVzPjXhU",
    "outputId": "cad4fa8d-1582-4497-c0ec-6f79d5c6fdd7"
   },
   "outputs": [],
   "source": [
    "vid = outputs.cpu().permute(0,2,3,4,1).numpy()[0]\n",
    "plt.imshow(vid[0,:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-Uar5YYHpKr-",
    "outputId": "a7e4fb68-e124-4a04-96a3-abb3b128d056"
   },
   "outputs": [],
   "source": [
    "outputs.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VjITMBDDpK3N"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
